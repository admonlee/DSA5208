{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32d1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passenger_count      6.00000\n",
      "trip_distance       31.47000\n",
      "extra                9.75000\n",
      "total_amount       169.24515\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File path\n",
    "file_path = 'nytaxi2022.csv'\n",
    "\n",
    "# Chunk size\n",
    "chunk_size = 3e6\n",
    "\n",
    "# Columns to check for outliers\n",
    "columns_to_check = ['passenger_count', 'trip_distance', 'extra', 'total_amount']\n",
    "\n",
    "# List to store 99th percentiles for each chunk\n",
    "percentiles_list = []\n",
    "\n",
    "# Read the dataset in chunks, only loading needed columns\n",
    "for chunk in pd.read_csv(file_path, usecols=columns_to_check, chunksize=chunk_size):\n",
    "    # Calculate the 99th percentile for each column in the chunk\n",
    "    percentiles = chunk[columns_to_check].quantile(0.999, numeric_only=True)\n",
    "    percentiles_list.append(percentiles)\n",
    "\n",
    "# Combine all percentiles into a DataFrame\n",
    "percentiles_df = pd.DataFrame(percentiles_list)\n",
    "\n",
    "# Find the maximum 99th percentile for each column\n",
    "max_99th_percentiles = percentiles_df.max()\n",
    "\n",
    "# Display the result\n",
    "print(max_99th_percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40181828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk, found 2562 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 2075 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 2655 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3259 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3090 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3225 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3892 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3958 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3887 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3557 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3110 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 2742 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 3623 rows exceeding 99th percentiles.\n",
      "Processed chunk, found 1406 rows exceeding 99th percentiles.\n",
      "       passenger_count  trip_distance  extra  total_amount  \\\n",
      "0                  1.0           0.00   0.00        282.80   \n",
      "1                  4.0          23.35   0.00        178.10   \n",
      "2                  1.0          31.90   1.75        147.10   \n",
      "3                  3.0          35.09   0.00        201.90   \n",
      "4                  1.0          42.25   0.00        130.30   \n",
      "...                ...            ...    ...           ...   \n",
      "43036              NaN          30.22   0.00        233.24   \n",
      "43037              NaN        3807.44   0.00         22.69   \n",
      "43038              NaN        1486.88   0.00         33.53   \n",
      "43039              NaN      116490.78   0.00         38.61   \n",
      "43040              NaN       45478.20   0.00         19.22   \n",
      "\n",
      "                   columns_exceeding  \n",
      "0                     [total_amount]  \n",
      "1                     [total_amount]  \n",
      "2                    [trip_distance]  \n",
      "3      [trip_distance, total_amount]  \n",
      "4                    [trip_distance]  \n",
      "...                              ...  \n",
      "43036                 [total_amount]  \n",
      "43037                [trip_distance]  \n",
      "43038                [trip_distance]  \n",
      "43039                [trip_distance]  \n",
      "43040                [trip_distance]  \n",
      "\n",
      "[43041 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to collect all rows exceeding the 99th percentile across all chunks\n",
    "exceeding_rows_list = []\n",
    "\n",
    "# Read the dataset in chunks and collect exceeding rows (only needed columns)\n",
    "for chunk in pd.read_csv(file_path, usecols=columns_to_check, chunksize=chunk_size):\n",
    "    # Boolean DataFrame: True where value exceeds 99th percentile\n",
    "    mask = chunk[columns_to_check] > max_99th_percentiles\n",
    "\n",
    "    # Rows where any column exceeds\n",
    "    exceeding_rows = mask.any(axis=1)\n",
    "\n",
    "    # Subset of rows exceeding\n",
    "    rows_exceeding_99th = chunk[exceeding_rows].copy()\n",
    "\n",
    "    # Add a new column listing which columns exceed\n",
    "    rows_exceeding_99th['columns_exceeding'] = mask[exceeding_rows].apply(\n",
    "        lambda x: list(x.index[x].values), axis=1\n",
    "    )\n",
    "\n",
    "    exceeding_rows_list.append(rows_exceeding_99th)\n",
    "\n",
    "    print(f\"Processed chunk, found {len(rows_exceeding_99th)} rows exceeding 99th percentiles.\")\n",
    "\n",
    "# Concatenate all exceeding rows into a single DataFrame\n",
    "if exceeding_rows_list:\n",
    "    all_exceeding_rows = pd.concat(exceeding_rows_list, ignore_index=True)\n",
    "else:\n",
    "    all_exceeding_rows = pd.DataFrame(columns=columns_to_check + ['columns_exceeding'])\n",
    "\n",
    "# Display all rows that exceed the 99th percentile in any chunk\n",
    "print(all_exceeding_rows)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
